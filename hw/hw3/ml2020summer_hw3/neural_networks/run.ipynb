{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. Please check the pdf file for more details.*\n",
    "\n",
    "In this exercise you will:\n",
    "    \n",
    "- implement the **forward** and **backward** operations for different layers in neural networks\n",
    "- implement a simple neural networks for classification\n",
    "\n",
    "Please note that **YOU CANNOT USE ANY MACHINE LEARNING PACKAGE SUCH AS SKLEARN** for any homework, unless you are asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic imports\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400)\n",
      "(4000, 400) (1, 4000)\n",
      "(1000, 400) (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "digit_data = sio.loadmat('digit_data.mat')\n",
    "X = digit_data['X']\n",
    "y = digit_data['y']\n",
    "_, num_cases = X.shape\n",
    "train_num_cases = num_cases * 4 // 5\n",
    "X = X.reshape((400, num_cases))\n",
    "X = X.transpose()\n",
    "print(X.shape)\n",
    "# X has the shape of (number of samples, number of pixels)\n",
    "train_data = X[:train_num_cases,:]\n",
    "train_label = y[:, :train_num_cases]\n",
    "test_data = X[train_num_cases:, :]\n",
    "test_label = y[:, train_num_cases:]\n",
    "print(train_data.shape,train_label.shape)\n",
    "print(test_data.shape,test_label.shape)\n",
    "weights = {}\n",
    "weights['fully1_weight'] = np.random.randn(400, 25) / 400\n",
    "weights['fully1_bias'] = np.random.rand(25, 1) \n",
    "weights['fully2_weight'] = np.random.randn(25, 10) / 25\n",
    "weights['fully2_bias'] = np.random.rand(10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. 1 loss:0.0662, accuracy:0.99\n",
      "  1. 2 loss:0.12, accuracy:0.98\n",
      "  1. 3 loss:0.0862, accuracy:0.98\n",
      "  1. 4 loss:0.151, accuracy:0.97\n",
      "  1. 5 loss:0.103, accuracy:0.96\n",
      "  1. 6 loss:0.056, accuracy:0.99\n",
      "  1. 7 loss:0.119, accuracy:0.96\n",
      "  1. 8 loss:0.0595, accuracy:1.0\n",
      "  1. 9 loss:0.07, accuracy:0.98\n",
      "  1.10 loss:0.124, accuracy:0.95\n",
      "  1.11 loss:0.0857, accuracy:0.98\n",
      "  1.12 loss:0.145, accuracy:0.96\n",
      "  1.13 loss:0.138, accuracy:0.97\n",
      "  1.14 loss:0.148, accuracy:0.96\n",
      "  1.15 loss:0.04, accuracy:1.0\n",
      "  1.16 loss:0.0795, accuracy:0.98\n",
      "  1.17 loss:0.1, accuracy:0.97\n",
      "  1.18 loss:0.167, accuracy:0.93\n",
      "  1.19 loss:0.178, accuracy:0.96\n",
      "  1.20 loss:0.0958, accuracy:0.98\n",
      "  1.21 loss:0.0968, accuracy:0.97\n",
      "  1.22 loss:0.13, accuracy:0.96\n",
      "  1.23 loss:0.121, accuracy:0.98\n",
      "  1.24 loss:0.0953, accuracy:0.98\n",
      "  1.25 loss:0.0765, accuracy:0.97\n",
      "  1.26 loss:0.0917, accuracy:0.98\n",
      "  1.27 loss:0.17, accuracy:0.95\n",
      "  1.28 loss:0.109, accuracy:0.98\n",
      "  1.29 loss:0.1, accuracy:0.97\n",
      "  1.30 loss:0.108, accuracy:0.98\n",
      "  1.31 loss:0.154, accuracy:0.96\n",
      "  1.32 loss:0.0704, accuracy:0.99\n",
      "  1.33 loss:0.145, accuracy:0.97\n",
      "  1.34 loss:0.157, accuracy:0.96\n",
      "  1.35 loss:0.178, accuracy:0.96\n",
      "  1.36 loss:0.107, accuracy:0.96\n",
      "  1.37 loss:0.135, accuracy:0.95\n",
      "  1.38 loss:0.0838, accuracy:0.97\n",
      "  1.39 loss:0.118, accuracy:0.97\n",
      "  1.40 loss:0.189, accuracy:0.93\n",
      "  2. 1 loss:0.0573, accuracy:1.0\n",
      "  2. 2 loss:0.107, accuracy:0.98\n",
      "  2. 3 loss:0.0903, accuracy:0.98\n",
      "  2. 4 loss:0.138, accuracy:0.98\n",
      "  2. 5 loss:0.0994, accuracy:0.97\n",
      "  2. 6 loss:0.0564, accuracy:0.99\n",
      "  2. 7 loss:0.121, accuracy:0.97\n",
      "  2. 8 loss:0.0697, accuracy:0.99\n",
      "  2. 9 loss:0.0739, accuracy:0.97\n",
      "  2.10 loss:0.121, accuracy:0.95\n",
      "  2.11 loss:0.0902, accuracy:0.98\n",
      "  2.12 loss:0.141, accuracy:0.97\n",
      "  2.13 loss:0.155, accuracy:0.95\n",
      "  2.14 loss:0.152, accuracy:0.94\n",
      "  2.15 loss:0.048, accuracy:1.0\n",
      "  2.16 loss:0.08, accuracy:0.99\n",
      "  2.17 loss:0.101, accuracy:0.97\n",
      "  2.18 loss:0.147, accuracy:0.96\n",
      "  2.19 loss:0.167, accuracy:0.96\n",
      "  2.20 loss:0.0984, accuracy:0.97\n",
      "  2.21 loss:0.0977, accuracy:0.98\n",
      "  2.22 loss:0.11, accuracy:0.96\n",
      "  2.23 loss:0.116, accuracy:0.98\n",
      "  2.24 loss:0.0801, accuracy:0.98\n",
      "  2.25 loss:0.0692, accuracy:0.97\n",
      "  2.26 loss:0.0958, accuracy:0.98\n",
      "  2.27 loss:0.15, accuracy:0.94\n",
      "  2.28 loss:0.108, accuracy:0.98\n",
      "  2.29 loss:0.0843, accuracy:0.97\n",
      "  2.30 loss:0.0971, accuracy:0.98\n",
      "  2.31 loss:0.145, accuracy:0.96\n",
      "  2.32 loss:0.0686, accuracy:0.98\n",
      "  2.33 loss:0.136, accuracy:0.97\n",
      "  2.34 loss:0.156, accuracy:0.94\n",
      "  2.35 loss:0.17, accuracy:0.95\n",
      "  2.36 loss:0.0996, accuracy:0.97\n",
      "  2.37 loss:0.128, accuracy:0.97\n",
      "  2.38 loss:0.0732, accuracy:0.98\n",
      "  2.39 loss:0.108, accuracy:0.96\n",
      "  2.40 loss:0.154, accuracy:0.95\n",
      "  3. 1 loss:0.059, accuracy:0.99\n",
      "  3. 2 loss:0.108, accuracy:0.97\n",
      "  3. 3 loss:0.0831, accuracy:0.98\n",
      "  3. 4 loss:0.131, accuracy:0.98\n",
      "  3. 5 loss:0.0931, accuracy:0.96\n",
      "  3. 6 loss:0.0522, accuracy:1.0\n",
      "  3. 7 loss:0.0997, accuracy:0.98\n",
      "  3. 8 loss:0.0568, accuracy:1.0\n",
      "  3. 9 loss:0.068, accuracy:0.98\n",
      "  3.10 loss:0.11, accuracy:0.96\n",
      "  3.11 loss:0.0832, accuracy:0.97\n",
      "  3.12 loss:0.126, accuracy:0.97\n",
      "  3.13 loss:0.147, accuracy:0.96\n",
      "  3.14 loss:0.142, accuracy:0.96\n",
      "  3.15 loss:0.0409, accuracy:1.0\n",
      "  3.16 loss:0.0744, accuracy:0.99\n",
      "  3.17 loss:0.09, accuracy:0.98\n",
      "  3.18 loss:0.143, accuracy:0.96\n",
      "  3.19 loss:0.155, accuracy:0.96\n",
      "  3.20 loss:0.0846, accuracy:0.97\n",
      "  3.21 loss:0.0979, accuracy:0.98\n",
      "  3.22 loss:0.112, accuracy:0.95\n",
      "  3.23 loss:0.112, accuracy:0.98\n",
      "  3.24 loss:0.0738, accuracy:0.98\n",
      "  3.25 loss:0.0616, accuracy:0.98\n",
      "  3.26 loss:0.0942, accuracy:0.98\n",
      "  3.27 loss:0.145, accuracy:0.93\n",
      "  3.28 loss:0.103, accuracy:0.97\n",
      "  3.29 loss:0.0837, accuracy:0.97\n",
      "  3.30 loss:0.0846, accuracy:0.98\n",
      "  3.31 loss:0.121, accuracy:0.97\n",
      "  3.32 loss:0.0697, accuracy:0.99\n",
      "  3.33 loss:0.123, accuracy:0.98\n",
      "  3.34 loss:0.142, accuracy:0.95\n",
      "  3.35 loss:0.159, accuracy:0.97\n",
      "  3.36 loss:0.104, accuracy:0.96\n",
      "  3.37 loss:0.113, accuracy:0.97\n",
      "  3.38 loss:0.0687, accuracy:0.98\n",
      "  3.39 loss:0.092, accuracy:0.99\n",
      "  3.40 loss:0.13, accuracy:0.97\n",
      "  4. 1 loss:0.0559, accuracy:1.0\n",
      "  4. 2 loss:0.0971, accuracy:0.98\n",
      "  4. 3 loss:0.0759, accuracy:0.97\n",
      "  4. 4 loss:0.125, accuracy:0.98\n",
      "  4. 5 loss:0.0885, accuracy:0.96\n",
      "  4. 6 loss:0.0505, accuracy:0.99\n",
      "  4. 7 loss:0.0879, accuracy:0.98\n",
      "  4. 8 loss:0.0533, accuracy:1.0\n",
      "  4. 9 loss:0.0665, accuracy:0.97\n",
      "  4.10 loss:0.104, accuracy:0.95\n",
      "  4.11 loss:0.0843, accuracy:0.96\n",
      "  4.12 loss:0.115, accuracy:0.97\n",
      "  4.13 loss:0.14, accuracy:0.94\n",
      "  4.14 loss:0.132, accuracy:0.96\n",
      "  4.15 loss:0.0373, accuracy:1.0\n",
      "  4.16 loss:0.0704, accuracy:0.99\n",
      "  4.17 loss:0.0867, accuracy:0.98\n",
      "  4.18 loss:0.14, accuracy:0.96\n",
      "  4.19 loss:0.144, accuracy:0.96\n",
      "  4.20 loss:0.0762, accuracy:0.98\n",
      "  4.21 loss:0.0892, accuracy:0.98\n",
      "  4.22 loss:0.0988, accuracy:0.95\n",
      "  4.23 loss:0.0943, accuracy:0.98\n",
      "  4.24 loss:0.0677, accuracy:0.99\n",
      "  4.25 loss:0.0563, accuracy:0.98\n",
      "  4.26 loss:0.0898, accuracy:0.98\n",
      "  4.27 loss:0.141, accuracy:0.96\n",
      "  4.28 loss:0.101, accuracy:0.97\n",
      "  4.29 loss:0.0871, accuracy:0.97\n",
      "  4.30 loss:0.0737, accuracy:0.98\n",
      "  4.31 loss:0.098, accuracy:0.97\n",
      "  4.32 loss:0.0582, accuracy:1.0\n",
      "  4.33 loss:0.116, accuracy:0.98\n",
      "  4.34 loss:0.129, accuracy:0.96\n",
      "  4.35 loss:0.145, accuracy:0.98\n",
      "  4.36 loss:0.105, accuracy:0.98\n",
      "  4.37 loss:0.0997, accuracy:0.97\n",
      "  4.38 loss:0.0599, accuracy:0.99\n",
      "  4.39 loss:0.0806, accuracy:0.99\n",
      "  4.40 loss:0.12, accuracy:0.98\n",
      "  5. 1 loss:0.0452, accuracy:1.0\n",
      "  5. 2 loss:0.083, accuracy:0.99\n",
      "  5. 3 loss:0.0672, accuracy:0.98\n",
      "  5. 4 loss:0.114, accuracy:0.98\n",
      "  5. 5 loss:0.0845, accuracy:0.97\n",
      "  5. 6 loss:0.0466, accuracy:1.0\n",
      "  5. 7 loss:0.0777, accuracy:0.98\n",
      "  5. 8 loss:0.054, accuracy:0.99\n",
      "  5. 9 loss:0.0711, accuracy:0.97\n",
      "  5.10 loss:0.105, accuracy:0.96\n",
      "  5.11 loss:0.0762, accuracy:0.97\n",
      "  5.12 loss:0.11, accuracy:0.97\n",
      "  5.13 loss:0.127, accuracy:0.98\n",
      "  5.14 loss:0.108, accuracy:0.98\n",
      "  5.15 loss:0.0333, accuracy:1.0\n",
      "  5.16 loss:0.0645, accuracy:0.98\n",
      "  5.17 loss:0.0719, accuracy:0.98\n",
      "  5.18 loss:0.141, accuracy:0.96\n",
      "  5.19 loss:0.136, accuracy:0.97\n",
      "  5.20 loss:0.0767, accuracy:0.98\n",
      "  5.21 loss:0.0829, accuracy:0.98\n",
      "  5.22 loss:0.0906, accuracy:0.98\n",
      "  5.23 loss:0.0795, accuracy:0.98\n",
      "  5.24 loss:0.0563, accuracy:1.0\n",
      "  5.25 loss:0.0462, accuracy:0.99\n",
      "  5.26 loss:0.0813, accuracy:0.98\n",
      "  5.27 loss:0.122, accuracy:0.98\n",
      "  5.28 loss:0.0928, accuracy:0.98\n",
      "  5.29 loss:0.0941, accuracy:0.98\n",
      "  5.30 loss:0.0774, accuracy:0.97\n",
      "  5.31 loss:0.0966, accuracy:0.97\n",
      "  5.32 loss:0.0511, accuracy:1.0\n",
      "  5.33 loss:0.1, accuracy:0.97\n",
      "  5.34 loss:0.119, accuracy:0.96\n",
      "  5.35 loss:0.133, accuracy:0.99\n",
      "  5.36 loss:0.0953, accuracy:0.98\n",
      "  5.37 loss:0.0911, accuracy:0.97\n",
      "  5.38 loss:0.0565, accuracy:1.0\n",
      "  5.39 loss:0.0924, accuracy:0.98\n",
      "  5.40 loss:0.118, accuracy:0.98\n",
      "  6. 1 loss:0.0402, accuracy:1.0\n",
      "  6. 2 loss:0.0723, accuracy:0.99\n",
      "  6. 3 loss:0.0615, accuracy:0.99\n",
      "  6. 4 loss:0.0993, accuracy:0.98\n",
      "  6. 5 loss:0.0791, accuracy:0.98\n",
      "  6. 6 loss:0.0488, accuracy:1.0\n",
      "  6. 7 loss:0.0783, accuracy:0.97\n",
      "  6. 8 loss:0.0562, accuracy:0.98\n",
      "  6. 9 loss:0.0841, accuracy:0.97\n",
      "  6.10 loss:0.11, accuracy:0.96\n",
      "  6.11 loss:0.072, accuracy:0.97\n",
      "  6.12 loss:0.109, accuracy:0.97\n",
      "  6.13 loss:0.126, accuracy:0.97\n",
      "  6.14 loss:0.102, accuracy:0.99\n",
      "  6.15 loss:0.0315, accuracy:1.0\n",
      "  6.16 loss:0.0612, accuracy:0.99\n",
      "  6.17 loss:0.0574, accuracy:0.98\n",
      "  6.18 loss:0.125, accuracy:0.97\n",
      "  6.19 loss:0.132, accuracy:0.97\n",
      "  6.20 loss:0.0814, accuracy:0.98\n",
      "  6.21 loss:0.0836, accuracy:0.98\n",
      "  6.22 loss:0.0951, accuracy:0.97\n",
      "  6.23 loss:0.0746, accuracy:0.99\n",
      "  6.24 loss:0.0566, accuracy:0.99\n",
      "  6.25 loss:0.0405, accuracy:0.99\n",
      "  6.26 loss:0.0699, accuracy:0.99\n",
      "  6.27 loss:0.101, accuracy:0.98\n",
      "  6.28 loss:0.0785, accuracy:0.98\n",
      "  6.29 loss:0.0852, accuracy:0.98\n",
      "  6.30 loss:0.0802, accuracy:0.97\n",
      "  6.31 loss:0.0983, accuracy:0.97\n",
      "  6.32 loss:0.0461, accuracy:1.0\n",
      "  6.33 loss:0.0928, accuracy:0.97\n",
      "  6.34 loss:0.117, accuracy:0.96\n",
      "  6.35 loss:0.125, accuracy:0.99\n",
      "  6.36 loss:0.0741, accuracy:0.98\n",
      "  6.37 loss:0.0724, accuracy:0.98\n",
      "  6.38 loss:0.052, accuracy:1.0\n",
      "  6.39 loss:0.0994, accuracy:0.98\n",
      "  6.40 loss:0.119, accuracy:0.98\n",
      "  7. 1 loss:0.0396, accuracy:1.0\n",
      "  7. 2 loss:0.0719, accuracy:0.99\n",
      "  7. 3 loss:0.0615, accuracy:0.98\n",
      "  7. 4 loss:0.0795, accuracy:0.98\n",
      "  7. 5 loss:0.0625, accuracy:0.99\n",
      "  7. 6 loss:0.0432, accuracy:1.0\n",
      "  7. 7 loss:0.0787, accuracy:0.98\n",
      "  7. 8 loss:0.0515, accuracy:0.98\n",
      "  7. 9 loss:0.0791, accuracy:0.97\n",
      "  7.10 loss:0.104, accuracy:0.96\n",
      "  7.11 loss:0.0604, accuracy:1.0\n",
      "  7.12 loss:0.102, accuracy:0.97\n",
      "  7.13 loss:0.136, accuracy:0.96\n",
      "  7.14 loss:0.0958, accuracy:0.99\n",
      "  7.15 loss:0.0321, accuracy:1.0\n",
      "  7.16 loss:0.0555, accuracy:0.99\n",
      "  7.17 loss:0.0484, accuracy:0.99\n",
      "  7.18 loss:0.112, accuracy:0.97\n",
      "  7.19 loss:0.116, accuracy:0.98\n",
      "  7.20 loss:0.083, accuracy:0.98\n",
      "  7.21 loss:0.0843, accuracy:0.98\n",
      "  7.22 loss:0.101, accuracy:0.96\n",
      "  7.23 loss:0.0743, accuracy:0.99\n",
      "  7.24 loss:0.0584, accuracy:1.0\n",
      "  7.25 loss:0.0383, accuracy:1.0\n",
      "  7.26 loss:0.0612, accuracy:0.99\n",
      "  7.27 loss:0.0837, accuracy:0.99\n",
      "  7.28 loss:0.0654, accuracy:0.98\n",
      "  7.29 loss:0.08, accuracy:0.98\n",
      "  7.30 loss:0.0761, accuracy:0.97\n",
      "  7.31 loss:0.0937, accuracy:0.97\n",
      "  7.32 loss:0.0437, accuracy:1.0\n",
      "  7.33 loss:0.0778, accuracy:0.98\n",
      "  7.34 loss:0.119, accuracy:0.97\n",
      "  7.35 loss:0.131, accuracy:0.97\n",
      "  7.36 loss:0.0681, accuracy:0.98\n",
      "  7.37 loss:0.0566, accuracy:1.0\n",
      "  7.38 loss:0.0492, accuracy:1.0\n",
      "  7.39 loss:0.0953, accuracy:0.97\n",
      "  7.40 loss:0.114, accuracy:0.98\n",
      "  8. 1 loss:0.0404, accuracy:1.0\n",
      "  8. 2 loss:0.076, accuracy:0.99\n",
      "  8. 3 loss:0.0636, accuracy:0.98\n",
      "  8. 4 loss:0.0666, accuracy:0.97\n",
      "  8. 5 loss:0.0498, accuracy:0.99\n",
      "  8. 6 loss:0.0402, accuracy:1.0\n",
      "  8. 7 loss:0.0819, accuracy:0.97\n",
      "  8. 8 loss:0.0488, accuracy:0.99\n",
      "  8. 9 loss:0.066, accuracy:0.97\n",
      "  8.10 loss:0.0901, accuracy:0.96\n",
      "  8.11 loss:0.0482, accuracy:1.0\n",
      "  8.12 loss:0.0919, accuracy:0.98\n",
      "  8.13 loss:0.124, accuracy:0.96\n",
      "  8.14 loss:0.0842, accuracy:0.98\n",
      "  8.15 loss:0.0351, accuracy:1.0\n",
      "  8.16 loss:0.0556, accuracy:1.0\n",
      "  8.17 loss:0.0513, accuracy:1.0\n",
      "  8.18 loss:0.102, accuracy:0.97\n",
      "  8.19 loss:0.104, accuracy:0.97\n",
      "  8.20 loss:0.0655, accuracy:0.99\n",
      "  8.21 loss:0.0759, accuracy:0.98\n",
      "  8.22 loss:0.0963, accuracy:0.96\n",
      "  8.23 loss:0.0747, accuracy:0.99\n",
      "  8.24 loss:0.0635, accuracy:0.99\n",
      "  8.25 loss:0.0401, accuracy:1.0\n",
      "  8.26 loss:0.0604, accuracy:0.99\n",
      "  8.27 loss:0.0843, accuracy:0.98\n",
      "  8.28 loss:0.0564, accuracy:0.99\n",
      "  8.29 loss:0.0682, accuracy:0.97\n",
      "  8.30 loss:0.0541, accuracy:0.99\n",
      "  8.31 loss:0.0841, accuracy:0.98\n",
      "  8.32 loss:0.045, accuracy:1.0\n",
      "  8.33 loss:0.0704, accuracy:0.99\n",
      "  8.34 loss:0.128, accuracy:0.98\n",
      "  8.35 loss:0.135, accuracy:0.97\n",
      "  8.36 loss:0.068, accuracy:0.97\n",
      "  8.37 loss:0.0464, accuracy:1.0\n",
      "  8.38 loss:0.0468, accuracy:1.0\n",
      "  8.39 loss:0.0771, accuracy:0.98\n",
      "  8.40 loss:0.101, accuracy:0.99\n",
      "  9. 1 loss:0.0466, accuracy:0.99\n",
      "  9. 2 loss:0.0769, accuracy:0.99\n",
      "  9. 3 loss:0.0698, accuracy:0.97\n",
      "  9. 4 loss:0.068, accuracy:0.97\n",
      "  9. 5 loss:0.0433, accuracy:0.99\n",
      "  9. 6 loss:0.0379, accuracy:1.0\n",
      "  9. 7 loss:0.0767, accuracy:0.98\n",
      "  9. 8 loss:0.0468, accuracy:1.0\n",
      "  9. 9 loss:0.0572, accuracy:0.97\n",
      "  9.10 loss:0.0792, accuracy:0.98\n",
      "  9.11 loss:0.0461, accuracy:1.0\n",
      "  9.12 loss:0.0834, accuracy:0.98\n",
      "  9.13 loss:0.104, accuracy:0.98\n",
      "  9.14 loss:0.068, accuracy:0.99\n",
      "  9.15 loss:0.032, accuracy:1.0\n",
      "  9.16 loss:0.0502, accuracy:1.0\n",
      "  9.17 loss:0.0493, accuracy:1.0\n",
      "  9.18 loss:0.0936, accuracy:0.96\n",
      "  9.19 loss:0.0921, accuracy:0.98\n",
      "  9.20 loss:0.0539, accuracy:1.0\n",
      "  9.21 loss:0.0619, accuracy:0.99\n",
      "  9.22 loss:0.0864, accuracy:0.98\n",
      "  9.23 loss:0.0635, accuracy:1.0\n",
      "  9.24 loss:0.0591, accuracy:0.99\n",
      "  9.25 loss:0.0401, accuracy:1.0\n",
      "  9.26 loss:0.0657, accuracy:0.98\n",
      "  9.27 loss:0.0963, accuracy:0.97\n",
      "  9.28 loss:0.0522, accuracy:0.99\n",
      "  9.29 loss:0.0598, accuracy:0.98\n",
      "  9.30 loss:0.0427, accuracy:1.0\n",
      "  9.31 loss:0.0739, accuracy:0.98\n",
      "  9.32 loss:0.0393, accuracy:1.0\n",
      "  9.33 loss:0.0574, accuracy:0.99\n",
      "  9.34 loss:0.127, accuracy:0.98\n",
      "  9.35 loss:0.131, accuracy:0.97\n",
      "  9.36 loss:0.0766, accuracy:0.97\n",
      "  9.37 loss:0.0495, accuracy:1.0\n",
      "  9.38 loss:0.0359, accuracy:1.0\n",
      "  9.39 loss:0.0602, accuracy:0.99\n",
      "  9.40 loss:0.0917, accuracy:0.99\n",
      " 10. 1 loss:0.0428, accuracy:1.0\n",
      " 10. 2 loss:0.0786, accuracy:0.99\n",
      " 10. 3 loss:0.0685, accuracy:0.97\n",
      " 10. 4 loss:0.0674, accuracy:0.97\n",
      " 10. 5 loss:0.0485, accuracy:0.99\n",
      " 10. 6 loss:0.0332, accuracy:1.0\n",
      " 10. 7 loss:0.063, accuracy:0.98\n",
      " 10. 8 loss:0.0392, accuracy:1.0\n",
      " 10. 9 loss:0.05, accuracy:0.99\n",
      " 10.10 loss:0.0802, accuracy:0.98\n",
      " 10.11 loss:0.0484, accuracy:0.99\n",
      " 10.12 loss:0.0828, accuracy:0.97\n",
      " 10.13 loss:0.0883, accuracy:0.98\n",
      " 10.14 loss:0.0593, accuracy:0.99\n",
      " 10.15 loss:0.0272, accuracy:1.0\n",
      " 10.16 loss:0.0439, accuracy:1.0\n",
      " 10.17 loss:0.0484, accuracy:1.0\n",
      " 10.18 loss:0.0955, accuracy:0.97\n",
      " 10.19 loss:0.0899, accuracy:0.98\n",
      " 10.20 loss:0.0486, accuracy:1.0\n",
      " 10.21 loss:0.0478, accuracy:0.99\n",
      " 10.22 loss:0.0754, accuracy:0.98\n",
      " 10.23 loss:0.0599, accuracy:1.0\n",
      " 10.24 loss:0.0523, accuracy:1.0\n",
      " 10.25 loss:0.0342, accuracy:1.0\n",
      " 10.26 loss:0.0674, accuracy:0.98\n",
      " 10.27 loss:0.103, accuracy:0.97\n",
      " 10.28 loss:0.0513, accuracy:1.0\n",
      " 10.29 loss:0.0501, accuracy:0.99\n",
      " 10.30 loss:0.0414, accuracy:1.0\n",
      " 10.31 loss:0.0703, accuracy:0.98\n",
      " 10.32 loss:0.0353, accuracy:1.0\n",
      " 10.33 loss:0.0516, accuracy:1.0\n",
      " 10.34 loss:0.109, accuracy:0.98\n",
      " 10.35 loss:0.119, accuracy:0.97\n",
      " 10.36 loss:0.0891, accuracy:0.97\n",
      " 10.37 loss:0.0624, accuracy:1.0\n",
      " 10.38 loss:0.0363, accuracy:1.0\n",
      " 10.39 loss:0.0555, accuracy:0.99\n",
      " 10.40 loss:0.0862, accuracy:0.99\n"
     ]
    }
   ],
   "source": [
    "# training setting\n",
    "weight_inc = {}\n",
    "for name in ('fully1_weight', 'fully1_bias', 'fully2_weight', 'fully2_bias'):\n",
    "    weight_inc[name] = np.zeros(weights[name].shape)\n",
    "batch_size = 100\n",
    "max_epoch = 10\n",
    "momW = 0.9\n",
    "wc = 0.0005\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training iterations\n",
    "from get_new_weight_inc import get_new_weight_inc \n",
    "from feedforward_backprop import feedforward_backprop\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for i in range(math.ceil(train_num_cases/batch_size)):\n",
    "        data = train_data[i * batch_size:min((i + 1) * batch_size, train_num_cases), :]\n",
    "        label = train_label[:, i * batch_size:min((i + 1) * batch_size, train_num_cases)]\n",
    "        # The feedforward and backpropgation processes\n",
    "        loss, accuracy, gradients = feedforward_backprop(data, label, weights)\n",
    "        print('{:3}.{:2} loss:{:.3}, accuracy:{}'.format(epoch + 1, i + 1, loss, accuracy))\n",
    "        # Updating weights\n",
    "        for name in ('fully1_weight', 'fully1_bias', 'fully2_weight', 'fully2_bias'):\n",
    "            weight_inc[name] = get_new_weight_inc(weight_inc[name], weights[name], momW, wc, learning_rate, gradients[name + '_grad'])\n",
    "            weights[name] += weight_inc[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.264, accuracy:0.922\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "loss, accuracy, _ = feedforward_backprop(test_data, test_label, weights)\n",
    "print('loss:{:.3}, accuracy:{}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
